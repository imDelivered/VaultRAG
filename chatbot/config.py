
# Hermit - Offline AI Chatbot for Wikipedia & ZIM Files
# Copyright (C) 2026 Hermit-AI, Inc.
#
# SPDX-License-Identifier: AGPL-3.0-or-later
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""Configuration constants."""

OLLAMA_CHAT_URL = "N/A" # Legacy/Deprecated
# Local Model Repositories
MODEL_ALETHEIA_3B = "Ishaanlol/Aletheia-Llama-3.2-3B" 
MODEL_QWEN_1_5B = "Qwen/Qwen2.5-1.5B-Instruct-GGUF"  # "Fast" Model
MODEL_QWEN_7B = "Qwen/Qwen2.5-7B-Instruct-GGUF"      # "Smart" Model
MODEL_NVIDIA_8B = "bartowski/nvidia_Llama-3.1-Nemotron-Nano-8B-v1-GGUF"

DEFAULT_MODEL = MODEL_NVIDIA_8B  # Using 8B model for best quality (unified with smart joints)
STRICT_RAG_MODE = False
MIN_ARTICLE_SCORE = 2.5
DEBUG = True

# API / External Model Configuration
API_MODE = False  # If True, use external API instead of local GGUF
API_BASE_URL = "http://localhost:1234/v1"  # Default (LM Studio / Ollama)
API_KEY = "lm-studio"  # Often ignored by local servers but required by spec
API_MODEL_NAME = "local-model"  # Passed in API request

# Multi-Joint RAG System Configuration
USE_JOINTS = True

# === TIERED MODEL ARCHITECTURE ===
# Fast Models (1.5B) for high-volume, low-complexity tasks
# Smart Models (8B) for reasoning, logic, and synthesis

ENTITY_JOINT_MODEL = MODEL_QWEN_1_5B
SCORER_JOINT_MODEL = MODEL_QWEN_1_5B
FILTER_JOINT_MODEL = MODEL_QWEN_1_5B

# Reasoning Joints (8B)
FACT_JOINT_MODEL = MODEL_NVIDIA_8B       # Verification requires logic
MULTI_HOP_JOINT_MODEL = MODEL_NVIDIA_8B  # Resolving recursive entities requires logic
COMPARISON_JOINT_MODEL = MODEL_NVIDIA_8B # Synthesizing comparisons requires logic

# Joint Temperatures
ENTITY_JOINT_TEMP = 0.1
SCORER_JOINT_TEMP = 0.0
FILTER_JOINT_TEMP = 0.1
FACT_JOINT_TEMP = 0.0

# Joint Timeout (not used for local inference but kept for compat)
JOINT_TIMEOUT = 30 # Increased for 7B model generation

# Adaptive RAG Configuration
ADAPTIVE_THRESHOLD = 3.0  # Lowered to trigger fewer expansions when data is present

# Global Context Window Configuration
DEFAULT_CONTEXT_SIZE = 8192

SYSTEM_PROMPT = (
    "You are a helpful, thorough AI assistant. When provided with context, "
    "you carefully read ALL of it to find the most accurate and complete answer. "
    "You synthesize information from multiple sources when relevant and always verify "
    "that your answer directly addresses what was asked."
)
