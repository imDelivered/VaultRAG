# Hermit â€” Offline AI Chatbot for Wikipedia & ZIM Files

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/)
[![CUDA Accelerated](https://img.shields.io/badge/CUDA-Accelerated-76B900.svg)](https://developer.nvidia.com/cuda-toolkit)

> ğŸ§  **A privacy-first, offline AI chatbot** powered by local LLMs and Retrieval-Augmented Generation (RAG). Chat with Wikipedia, documentation, or any ZIM archive â€” completely offline, 100% private.

**No cloud. No API keys. No data leaves your machine.**

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ”’ **100% Offline** | Runs entirely on your local machine after initial setup |
| ğŸ§  **Local LLM** | Uses GGUF models via `llama-cpp-python` â€” no OpenAI needed |
| ğŸ“š **Wikipedia RAG** | Chat with offline Wikipedia using [Kiwix ZIM files](https://library.kiwix.org/) |
| âš¡ **GPU Accelerated** | CUDA support for fast inference on NVIDIA GPUs |
| ğŸ¯ **Multi-Joint Architecture** | Unique 3-stage reasoning pipeline for accurate answers |
| ğŸ” **Hybrid Search** | Combines keyword (BM25) + semantic (FAISS) retrieval |
| ğŸ›¡ï¸ **Privacy First** | Your data never leaves your computer |

---

## ğŸš€ Quick Start

### Prerequisites

- **OS**: Linux (Ubuntu/Debian tested)
- **GPU**: NVIDIA RTX 3060+ recommended (8GB+ VRAM)
- **RAM**: 12GB+ system memory
- **Python**: 3.8+

### Installation

```bash
# Clone the repository
git clone https://github.com/imDelivered/Hermit-AI.git
cd Hermit-AI

# Run the setup script
chmod +x setup.sh
./setup.sh
```

> **What setup.sh does:**
> - Installs system dependencies (Python, libzim, CUDA toolkit)
> - Creates an isolated virtual environment
> - Installs PyTorch with CUDA 12.1 support
> - Compiles `llama-cpp-python` with GPU acceleration
> - Creates the `hermit` command system-wide

### Add Your Knowledge Base

Download a ZIM file from [Kiwix Library](https://library.kiwix.org/) and place it in the project root:

```bash
# Example: Download Wikipedia
wget https://download.kiwix.org/zim/wikipedia_en_all_maxi.zim
```

### Launch Hermit

```bash
hermit              # Start the GUI
hermit --cli        # Start in terminal mode
hermit --debug      # Start with verbose logging
```

---

## ğŸ—ï¸ How It Works â€” Multi-Joint RAG Architecture

Hermit uses a unique **Multi-Joint Architecture** that chains specialized reasoning stages:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query: "How did the Roman Empire fall?"                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Joint 1] Entity Extraction                                        â”‚
â”‚     â†’ Extracts: "Roman Empire", "fall", "decline"                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Retrieval] Hybrid Search (BM25 + FAISS)                           â”‚
â”‚     â†’ Finds 15 candidate articles from ZIM file                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Joint 2] Article Scoring                                          â”‚
â”‚     â†’ Scores articles 0-10, selects top 5                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Joint 3] Chunk Filtering                                          â”‚
â”‚     â†’ Extracts most relevant paragraphs                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Generation] Final Answer                                          â”‚
â”‚     â†’ LLM synthesizes answer from verified facts                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Multi-Joint?**
- âœ… Reduces hallucinations by grounding in retrieved facts
- âœ… Uses specialized small models for each reasoning step
- âœ… GBNF grammar enforcement ensures valid JSON at every stage
- âœ… Just-in-time indexing â€” no pre-processing wait

---

## âš™ï¸ Configuration

### Models

Edit `chatbot/config.py` to customize:

```python
# Default model (auto-downloads from Hugging Face)
DEFAULT_MODEL = "Ishaanlol/Aletheia-Llama-3.2-3B"

# Joint models (entity extraction, scoring, filtering)
ENTITY_JOINT_MODEL = DEFAULT_MODEL
SCORER_JOINT_MODEL = DEFAULT_MODEL
FILTER_JOINT_MODEL = DEFAULT_MODEL

# Context window size
DEFAULT_CONTEXT_SIZE = 16384
```

### Supported Models

Any GGUF model from Hugging Face works. Recommended:
- **Aletheia 3B** (default) â€” Fast, accurate
- **Llama 3.2 3B** â€” Great reasoning
- **Mistral 7B** â€” More capable, needs 12GB+ VRAM

---

## ğŸ› ï¸ Troubleshooting

### "Failed to create llama_context" (Out of Memory)
Your GPU ran out of VRAM. Solutions:
1. Close other GPU applications
2. Use a smaller model
3. Reduce `DEFAULT_CONTEXT_SIZE` in config

### "CUDA not available"
If Hermit uses CPU instead of GPU:
1. Ensure NVIDIA drivers are installed: `nvidia-smi`
2. Re-run `./setup.sh` to reinstall PyTorch with CUDA

### "Dependencies missing"
```bash
./setup.sh  # Re-run to fix broken packages
```

---

## ğŸ—‘ï¸ Uninstallation

```bash
./uninstall.sh
```

The GUI uninstaller lets you selectively remove:
- âœ… Virtual environment
- âœ… Downloaded models
- âœ… Search indexes
- ğŸ›¡ï¸ **Your ZIM files are always protected**

---

## ğŸ¤ Contributing

Contributions welcome! Please read the codebase and open a PR.

---

## ğŸ“œ License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.

See [LICENSE](LICENSE) for details.

---

## â­ Star History

If you find Hermit useful, please give it a star! It helps others discover the project.

---

<p align="center">
  <b>Hermit</b> â€” Your offline AI companion ğŸ§™â€â™‚ï¸
</p>
